{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session, session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "------I was to use this before class but actually------\n",
    "------We can use SQL instead of ORM------YES!----------\n",
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()\n",
    "\n",
    "# Save references to each table\n",
    "Station = Base.classes.station\n",
    "Measurement = Base.classes.measurement\n",
    "\n",
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)\n",
    "---------------------THANK YOU!------------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "measure_df = pd.read_sql(\"SELECT * FROM measurement ORDER BY date DESC\", conn)\n",
    "measure_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestDate1 = dt.date(2017, 8, 23)\n",
    "postDate1 = latestDate1 - dt.timedelta(days=365)\n",
    "print(f'Post Date in last 12 monts : {postDate1} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the date 1 year ago from the last data point in the database\n",
    "q1 = '''\n",
    "\n",
    "SELECT * FROM measurement\n",
    "WHERE date BETWEEN '2016-08-23' AND '2017-08-23'\n",
    "ORDER BY date DESC;\n",
    "'''\n",
    "#\n",
    "\n",
    "last12mnts = pd.read_sql(q1, conn)\n",
    "last12mnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a query to retrieve the date and precipitation scores\n",
    "prcp12 = last12mnts.loc[:, ['date', 'prcp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "prcp12.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by date #ascending\n",
    "prcp12.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp12 = prcp12.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcp12.to_csv('prcp.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "prcp12.plot(figsize = (12, 8), color='firebrick')\n",
    "\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.ylabel('Precipitation (Inches)', fontsize=15)\n",
    "plt.title(\"The last 12 months precipitation in Hawaii\", fontsize=17)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.xticks([], [])\n",
    "\n",
    "plt.savefig(\"outputs/precipitation.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "prcp12.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "q2 = '''\n",
    "\n",
    "SELECT COUNT(DISTINCT station) AS station_counts\n",
    "FROM measurement\n",
    "\n",
    "'''\n",
    "\n",
    "station_count = pd.read_sql(q2, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationCountValue = station_count.iloc[0,0]\n",
    "print(f'Station Counts : {stationCountValue} stations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "q3 = '''\n",
    "\n",
    "SELECT station, COUNT(*) AS count_frequency\n",
    "FROM measurement\n",
    "GROUP BY station\n",
    "ORDER BY count_frequency DESC;\n",
    "'''\n",
    "mostActiveCount = pd.read_sql(q3, conn)\n",
    "mostActiveCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostActiveStation = mostActiveCount.iloc[0,0]\n",
    "mostActiveValue = mostActiveCount.iloc[0,1]\n",
    "\n",
    "print(f'Most Observation Station : {mostActiveStation}')\n",
    "print(f'Obsevation Frequency : {mostActiveValue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature of the most active station?\n",
    "q4 = '''\n",
    "\n",
    "SELECT \n",
    "    station,\n",
    "    MAX(tobs) AS max_temp,\n",
    "    MIN(tobs) AS min_temp,\n",
    "    round(AVG(tobs), 2) AS avg_temp    \n",
    "FROM measurement\n",
    "WHERE station == 'USC00519281';\n",
    "'''\n",
    "mostActive_tobs = pd.read_sql(q4, conn)\n",
    "mostActive_tobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "q5 = '''\n",
    "\n",
    "SELECT \n",
    "    station,\n",
    "    MAX(tobs) AS max_temp  \n",
    "FROM measurement;\n",
    "'''\n",
    "max_tobs_station = pd.read_sql(q5, conn)\n",
    "max_tobs_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the last 12 months of temperature observation data for 'this station' \n",
    "q6 = '''\n",
    "\n",
    "SELECT station, date, tobs\n",
    "FROM measurement\n",
    "WHERE station == 'USC00519397'\n",
    "ORDER BY date DESC\n",
    "\n",
    "'''\n",
    "# To find the lastest date\n",
    "dateDescending = pd.read_sql(q6, conn)\n",
    "dateDescending.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the postdate in last 12 months\n",
    "latestDate2 = dt.date(2017, 8, 23)\n",
    "postDate2 = latestDate2 - dt.timedelta(days=365)\n",
    "print(f'Post Date in last 12 monts : {postDate2} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7 = '''\n",
    "\n",
    "SELECT date, tobs \n",
    "FROM measurement\n",
    "WHERE station == 'USC00519397'\n",
    "AND date BETWEEN '2016-08-23' AND '2017-08-23';\n",
    "'''\n",
    "tobs12 = pd.read_sql(q7, conn)\n",
    "tobs12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and plot the results as a histogram\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "x = tobs12['tobs']\n",
    "\n",
    "#figsize = (12,8)\n",
    "\n",
    "ax.hist(x, bins=12,label='tobs', color='orange')\n",
    "\n",
    "ax.set_title('Last 12 months of Temp. Obsevation from USC00519397', fontsize=15)\n",
    "ax.set_xlabel('Temp', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.grid(alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temparature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    q8 = '''\n",
    "\n",
    "    SELECT \n",
    "        MIN(tobs) as min_temp,\n",
    "        AVG(tobs) as avg_temp,\n",
    "        MAX(tobs) as max_temp\n",
    "    FROM measurement\n",
    "    WHERE date IN (start_date, end_date)\n",
    "    '''\n",
    "    tempBySelectedDate = pd.read_sql(q8, conn)\n",
    "    \n",
    "    min_temp, avg_temp, max_temp = tempBySelectedDate[0]\n",
    "    \n",
    "    #return a list\n",
    "    return [('Trip Min Temp:', min_temp),\n",
    "           ('Trip Avg Temp:', avg_temp),\n",
    "           ('Trip Max Temp:', max_temp)\n",
    "           ]\n",
    " \n",
    "    #return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        #filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "#function usage example\n",
    "#print(calc_temps('2016-02-28', '2016-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_trip_on = input(\"Enter the trip Start Date in 'YYYY-MM-DD' format: \")\n",
    "end_trip_on = input(\"Enter the trip End Date in 'YYYY-MM-DD' format: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Rainfall Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
